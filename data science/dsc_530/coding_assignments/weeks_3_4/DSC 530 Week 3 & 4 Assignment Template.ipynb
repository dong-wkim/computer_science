{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZp4Be3z4eJA"
   },
   "source": [
    "*  DSC 530 Data Exploration and Analysis \n",
    "*  Week 3 & 4 Coding Assignment\n",
    "*  Due: 06/10/2025 07:00 CET\n",
    "*  Dong Woon Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBUGf73h52Ow"
   },
   "source": [
    "# Week 3 & 4 Coding Assignment Checklist:\n",
    "## From Chapter 1 of Hands-On Data Analysis with Pandas: (DONE)\n",
    "- [x] Exercise 4\n",
    "- [x] Exercise 5\n",
    "- [x] Exercise 6\n",
    "- [x] Exercise 7\n",
    "- [x] Exercise 8\n",
    "\n",
    "## From Chapter 2 of Hands-On Data Analysis with Pandas: (DONE)\n",
    "- [x] Exercise 1\n",
    "- [x] Exercise 2\n",
    "- [x] Exercise 3\n",
    "- [x] Exercise 4\n",
    "- [x] Exercise 5\n",
    "- [x] Exercise 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W58yhTdztMCt",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W58yhTdztMCt"
   },
   "source": [
    "## Chapter 1, Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VN8_iWo6BpH"
   },
   "source": [
    "Run the code in the first cell of the exercises.ipynb notebook. It will give you a list of 100 values to work with for the rest of the exercises in this chapter. Be sure to treat these values as a sample of the population.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1730912064903,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "y7SezWOd6CiF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[844000.0, 758000.0, 421000.0, 259000.0, 511000.0, 405000.0, 784000.0, 303000.0, 477000.0, 583000.0, 908000.0, 505000.0, 282000.0, 756000.0, 618000.0, 251000.0, 910000.0, 983000.0, 810000.0, 902000.0, 310000.0, 730000.0, 899000.0, 684000.0, 472000.0, 101000.0, 434000.0, 611000.0, 913000.0, 967000.0, 477000.0, 865000.0, 260000.0, 805000.0, 549000.0, 14000.0, 720000.0, 399000.0, 825000.0, 668000.0, 1000.0, 494000.0, 868000.0, 244000.0, 325000.0, 870000.0, 191000.0, 568000.0, 239000.0, 968000.0, 803000.0, 448000.0, 80000.0, 320000.0, 508000.0, 933000.0, 109000.0, 551000.0, 707000.0, 547000.0, 814000.0, 540000.0, 964000.0, 603000.0, 588000.0, 445000.0, 596000.0, 385000.0, 576000.0, 290000.0, 189000.0, 187000.0, 613000.0, 657000.0, 477000.0, 90000.0, 758000.0, 877000.0, 923000.0, 842000.0, 898000.0, 923000.0, 541000.0, 391000.0, 705000.0, 276000.0, 812000.0, 849000.0, 895000.0, 590000.0, 950000.0, 580000.0, 451000.0, 660000.0, 996000.0, 917000.0, 793000.0, 82000.0, 613000.0, 486000.0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "salaries = [round(random.random()*1000000, -3) for _ in range(100)]\n",
    "print(salaries)\n",
    "# Currently, this code generated a list of random values as salaries for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "MdOIcbCHaBw1",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Chapter 1, Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FovE22tGZmIm"
   },
   "source": [
    "Using the data from exercise 4, calculate the following statistics without importing anything from the [statistics module](https://docs.python.org/3/library/statistics.html) in the Python standard library, and then confirm your results match up to those that are obtained when using the statistics module (where possible):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8Rec4n_6-aH"
   },
   "source": [
    "Tip from instructor: You can use [Pandas](https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html) or [Numpy](https://numpy.org/doc/stable/reference/routines.statistics.html) for the initial calculation and then check against other Python library/package such as [statistics module](https://docs.python.org/3/library/statistics.html), or [SciPy Statistics](https://docs.scipy.org/doc/scipy/reference/stats.html). Part a of Exercise 5 is completed to illustrate the process for you, you can decide how to go about the other problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x35gdEpZAWYy"
   },
   "source": [
    "Exercise 5(a) Mean - with exmaples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1730912065095,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "KtMDgGXH-Kzp"
   },
   "outputs": [],
   "source": [
    "# Run this code to make alias to shorted the typed name\n",
    "# You can do this as the 1st thing in any notebook or later, but you only need to do this once\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730912065095,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "whF42naK7J0Q",
    "outputId": "ee9a10d1-d3e0-4e27-ad6c-2b252b850134"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(585690.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using numpy.mean\n",
    "np.mean(salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1730912065095,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "r5k88RGu-5_9",
    "outputId": "30aaa949-dc4a-40a6-f20d-6dcbb313cb43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585690.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using statistics module\n",
    "import statistics # no need to re-run this after import\n",
    "# You have to import this standard library before using its mean function\n",
    "statistics.mean(salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730912065095,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "Pu2j7DMrAdYC",
    "outputId": "eb9098cb-1100-4f9b-b0a6-e6793077d3bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(585690.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Pandas\n",
    "# If you choose to use Pandas functions, you have to convert the list to a Series, otherwise it will gives an error\n",
    "salaries_series = pd.Series(salaries)\n",
    "# For Pandas function, when you placed a dot after a variable or other functions, it is referred as a \"method chaining\" appraoch.\n",
    "salaries_series.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730912065095,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "Kj1-5GzHBLoH",
    "outputId": "d422e5ad-d654-457d-b078-2803fd9120e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(585690.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using SciPy Statistics\n",
    "from scipy import stats\n",
    "stats.tmean(salaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0HPVtEaZsQp"
   },
   "source": [
    "Exercise 5(b) Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730912065095,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "a_J7K9DiZta7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589000.0\n",
      "589000.0\n"
     ]
    }
   ],
   "source": [
    "# Your 1st appraoch\n",
    "import numpy as np\n",
    "print(np.median(salaries))\n",
    "\n",
    "import pandas as pd\n",
    "salaries_series = pd.Series(salaries)\n",
    "print(salaries_series.median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730912065095,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "3XoPEbUSC59O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589000.0\n",
      "589000.0\n"
     ]
    }
   ],
   "source": [
    "# Using statistics module\n",
    "import statistics\n",
    "print(statistics.median(salaries))\n",
    "\n",
    "import scipy.stats as stats\n",
    "print(stats.scoreatpercentile(salaries,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njc5N6MPZuCJ"
   },
   "source": [
    "Exercise 5(c) Mode\n",
    "\n",
    "Hint from textbook: Check out the [Counter class](https://docs.python.org/3/library/collections.html#collections.Counter) in the collections module of the standard library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730912065095,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "eUxHtJpaZwb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(477000.0, 3)]\n"
     ]
    }
   ],
   "source": [
    "# Your 1st approach\n",
    "from collections import Counter\n",
    "c = Counter(salaries)\n",
    "print(c.most_common(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730912065095,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "5us8aS3tDRgo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477000.0\n"
     ]
    }
   ],
   "source": [
    "# Using statistics module\n",
    "print(statistics.mode(salaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZMkHU0GZzBZ"
   },
   "source": [
    "Exercise 5(d) **Sample** Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730912065095,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "2nk3H2vnZyYG",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70664054444.44444\n"
     ]
    }
   ],
   "source": [
    "# Your 1st approach\n",
    "print(np.var(salaries,ddof=1)) # for sample variance use degree of freedom = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730912065095,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "Kes7bKC6DpHy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70664054444.44444\n"
     ]
    }
   ],
   "source": [
    "# Using statistics module\n",
    "print(statistics.variance(salaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nwc6aWm9Drpa"
   },
   "source": [
    "Exercise 5(e) **Sample** Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1730912065242,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "VmQlqzmcDry7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265827.11382484\n"
     ]
    }
   ],
   "source": [
    "# Your 1st approach\n",
    "print(np.std(salaries,ddof=1)) # for sample standard deviation use degree of freedom = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730912065242,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "5nY4bBZbDr1-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265827.11382484\n"
     ]
    }
   ],
   "source": [
    "# Using statistics module\n",
    "print(statistics.stdev(salaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC7NFyYraBw2"
   },
   "source": [
    "## Chapter 1, Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAvZKrazEXu_"
   },
   "source": [
    "Using the data from exercise 4, calculate the following statistics using the functions in the statistics module where appropriate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBtvaLKBEjfy"
   },
   "source": [
    "Exercise 6(a) Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730912065242,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "bv2g0VJVaBw2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000.0\n",
      "995000.0\n"
     ]
    }
   ],
   "source": [
    "# Hint:there is no function called \"Range\". However, what does it means to see a range of values?\n",
    "# Your solution\n",
    "min = np.min(salaries)\n",
    "max = np.max(salaries)\n",
    "range = max - min\n",
    "print(range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EF5GSXzSErcg"
   },
   "source": [
    "Exercise 6(b) Coefficient of Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730912065242,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "dHKWpNtRE4QX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.39%\n"
     ]
    }
   ],
   "source": [
    "# Hint: Coefficient of Variation (CV) is defined as the ratio of standard deviation to the mean in Hands-on Data Analysis with Pandas.\n",
    "# Your solution\n",
    "std = statistics.stdev(salaries)\n",
    "mean = statistics.mean(salaries)\n",
    "cv = std/mean\n",
    "print(str(round(cv*100,2)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5V01v5lEwVp"
   },
   "source": [
    "Exercise 6(c) Interquartile Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730912065242,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "4PN_NYNL5s0g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413250.0\n"
     ]
    }
   ],
   "source": [
    "# Hint: Interquartile range (IQR) is presented as the difference of the 75% and 25% quantile in Chapter 1 of Practical Statistics for Data Scientisits Textbook\n",
    "# OR you can find the values in each quartile and then substract Quantile 3 with Quantile 1 as in Chapter 1 of Hands-on Data Analysis with Pandas\n",
    "# Your solution\n",
    "Q1 = stats.scoreatpercentile(salaries,25)\n",
    "Q3 = stats.scoreatpercentile(salaries,75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPfqZBnfE7OE"
   },
   "source": [
    "Exercise 6(d) Quartile coefficient of dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730912065242,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "5x6rbXPxaBw4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.338660110633067\n"
     ]
    }
   ],
   "source": [
    "# Once you determined the 1st and 3rd quantile values from 6(c), you can use it for this calculation\n",
    "# Refer to the Quartile coefficient of dispersion formula in Chapter 1 of Hands-on Data Analysis with Pandas\n",
    "# Your solution\n",
    "QCD = (Q3 - Q1)/(Q3 + Q1)\n",
    "print(QCD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tn0nOQb_9JDn"
   },
   "source": [
    "## Chapter 1, Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSmLElbyaBw5"
   },
   "source": [
    "Scale the data created in exercise 4 using the following strategies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_RkZgvVLv9a"
   },
   "source": [
    "Exercise 7(a) Min-max Scaling (Normalizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1730912065242,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "xmr4QDdpL39a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84723618 0.76080402 0.42211055 0.25929648 0.51256281 0.40603015\n",
      " 0.78693467 0.30351759 0.47839196 0.58492462 0.91155779 0.50653266\n",
      " 0.28241206 0.75879397 0.6201005  0.25125628 0.91356784 0.98693467\n",
      " 0.81306533 0.90552764 0.31055276 0.73266332 0.90251256 0.68643216\n",
      " 0.47336683 0.10050251 0.43517588 0.61306533 0.91658291 0.97085427\n",
      " 0.47839196 0.86834171 0.26030151 0.8080402  0.55075377 0.01306533\n",
      " 0.72261307 0.4        0.8281407  0.67035176 0.         0.49547739\n",
      " 0.87135678 0.24422111 0.32562814 0.87336683 0.19095477 0.56984925\n",
      " 0.23919598 0.9718593  0.80603015 0.44924623 0.07939698 0.32060302\n",
      " 0.50954774 0.93668342 0.10854271 0.55276382 0.70954774 0.54874372\n",
      " 0.81708543 0.54170854 0.9678392  0.60502513 0.58994975 0.44623116\n",
      " 0.59798995 0.38592965 0.57788945 0.29045226 0.18894472 0.18693467\n",
      " 0.61507538 0.65929648 0.47839196 0.08944724 0.76080402 0.88040201\n",
      " 0.92663317 0.84522613 0.90150754 0.92663317 0.54271357 0.3919598\n",
      " 0.70753769 0.27638191 0.81507538 0.85226131 0.89849246 0.5919598\n",
      " 0.95376884 0.58190955 0.45226131 0.66231156 1.         0.92060302\n",
      " 0.7959799  0.08140704 0.61507538 0.48743719]\n"
     ]
    }
   ],
   "source": [
    "# Refer to the Scaling data section of your reading in Chapter 1 of Hands-on Data Analysis with Pandas\n",
    "# You can calculate this value by following the formula in the textbook or see the example in the solution\n",
    "# You can also test out the scikit-learn function \"MinMaxScaler\", which requires transforming the data in 2D array before applying the scaler. This is a common approach in machine learning.\n",
    "# Your solution\n",
    "\n",
    "# scaled.a = min-max\n",
    "# scaled.b = z-scored\n",
    "\n",
    "salaries_array = np.array(salaries)\n",
    "min_max_scaled = (salaries_array - min)/range\n",
    "print(min_max_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCBJyFsOL3iY"
   },
   "source": [
    "Exercise 7(b) Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1730912065242,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "vRVdK9dAaBw5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97172179  0.64820325 -0.61953801 -1.22895665 -0.28097209 -0.6797275\n",
      "  0.74601118 -1.06343554 -0.40887477 -0.01011936  1.21247978 -0.30354315\n",
      " -1.14243425  0.64067957  0.12154516 -1.2590514   1.22000347  1.49461804\n",
      "  0.84381912  1.18990872 -1.03710263  0.54287164  1.17862319  0.36982683\n",
      " -0.42768399 -1.82332793 -0.57063404  0.09521226  1.231289    1.43442854\n",
      " -0.40887477  1.05072051 -1.22519481  0.8250099  -0.13802204 -2.15060831\n",
      "  0.5052532  -0.70229856  0.90024677  0.30963734 -2.19951228 -0.34492343\n",
      "  1.06200604 -1.28538431 -0.98067498  1.06952973 -1.48476201 -0.06654701\n",
      " -1.30419352  1.43819039  0.81748621 -0.51796823 -1.90232664 -0.9994842\n",
      " -0.29225762  1.30652587 -1.79323318 -0.13049835  0.45634923 -0.14554572\n",
      "  0.85886649 -0.17187863  1.42314301  0.06511751  0.00868986 -0.52925376\n",
      "  0.03878461 -0.75496437 -0.03645226 -1.1123395  -1.4922857  -1.49980938\n",
      "  0.10273595  0.26825706 -0.40887477 -1.8647082   0.64820325  1.09586263\n",
      "  1.26890743  0.96419811  1.17486134  1.26890743 -0.16811679 -0.73239331\n",
      "  0.44882555 -1.16500531  0.8513428   0.99053101  1.16357581  0.01621355\n",
      "  1.37047721 -0.02140489 -0.5066827   0.27954259  1.54352201  1.24633637\n",
      "  0.77986778 -1.89480295  0.10273595 -0.37501818]\n"
     ]
    }
   ],
   "source": [
    "# Refer to the Scaling data section of your reading in Chapter 1 of Hands-on Data Analysis with Pandas\n",
    "# You can calculate this value by following the formula in the textbook or see the example in the solution\n",
    "# You can also test out the z-score method in Scipy Stats (2D array is needed)\n",
    "# Your solution\n",
    "\n",
    "z_score = (salaries_array - mean)/std\n",
    "print(z_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwpcBvyq427F"
   },
   "source": [
    "## Chapter 1, Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQfyPjukUPCz"
   },
   "source": [
    "Using the scaled data from exercise 7, calculate the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SK2n_glSFUzU"
   },
   "source": [
    "Note. There is some preparation work to create the normalized (scaled) vs. standardized dataset before calculating covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1730912065242,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "UE_E0xiBUiKi",
    "outputId": "c1a05b24-fc59-484c-8726-2983b464f595"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84723618],\n",
       "       [0.76080402],\n",
       "       [0.42211055],\n",
       "       [0.25929648],\n",
       "       [0.51256281],\n",
       "       [0.40603015],\n",
       "       [0.78693467],\n",
       "       [0.30351759],\n",
       "       [0.47839196],\n",
       "       [0.58492462]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you did not setup a scaled data or standardized data with z-score approach, you can use the following codes.\n",
    "# Scaled data aka normalized data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Make an array of salaries\n",
    "salaries_array = np.array(salaries)\n",
    "# Reshape the data to 2D (one feature)\n",
    "salaries_2d = salaries_array.reshape(-1, 1)\n",
    "# Scaled the data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(salaries_2d)\n",
    "# Optionally, transform the data. scaled_salaries in the scaled data for use in next step\n",
    "scaled_salaries = scaler.transform(salaries_2d)\n",
    "# Preview the first 10 values. Noticed the double [] that shows the 2D shape\n",
    "scaled_salaries[:10]\n",
    "# This will print the shape if you would like to check\n",
    "# scaled_salaries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1730912065242,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "L_GSj2r49m_j",
    "outputId": "23a7f434-62f5-4fb9-c4f3-f67a6bb342d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97661715,  0.65146878, -0.62265912, -1.23514791, -0.28238758,\n",
       "       -0.68315184,  0.74976945, -1.06879293, -0.41093461, -0.01017034])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardized version of the salary data (z-score)\n",
    "from scipy import stats\n",
    "# Assign a new variable `standardized_salary` to store the standarized data\n",
    "standardized_salary = stats.zscore(salaries_array)\n",
    "# Preview the first 10 values. This is a 1 dimension object\n",
    "standardized_salary[:10]\n",
    "# This will print the shape if you would like to check\n",
    "# standardized_salary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADXhJZDbUSSf"
   },
   "source": [
    "Exercise 8(a) The covariance between the standardized and normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730912065242,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "ALXqzgFH42LS",
    "outputId": "1e16b4f8-221b-4093-aeee-847c2e30b281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.267162928467176\n"
     ]
    }
   ],
   "source": [
    "# Covariance can be calculated with numpy\n",
    "# When the (normalized) scaled_salaries varaible was created, it was created as a 2D array.\n",
    "# We will have to 'flatten' it to match the shape of the standardized_salary before calculation.\n",
    "#scaled_salaries = np.array(scaled_salaries).flatten()\n",
    "\n",
    "# Now calculate the covariance\n",
    "#cov_calculated = np.cov(scaled_salaries, standardized_salary)\n",
    "#print(cov_calculated)\n",
    "\n",
    "min_max_scaled = np.array(min_max_scaled).flatten()\n",
    "z_score = np.array(z_score).flatten()\n",
    "# cov = np.cov(min_max_scaled, z_score, ddof =2)\n",
    "cov = statistics.covariance(min_max_scaled,z_score)\n",
    "print(cov) # Re-do to get 0.2685?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKFbk4lF_cnI"
   },
   "source": [
    "Note: How to interpret this output? The covariance function produce a 2X2 covariance matrix, the off-diagonal elements present the covariance of the 2 sets of values. Therefore 0.2685 is the output for intrepretation. Since the covariance estimate is positive, it indicates a positive relationship (moving in the same direction), and we don't know how \"strong\" this relationship and therefore correlation will help us understand this better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730912065242,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "jROQX8JYaczQ",
    "outputId": "d022ba01-4f47-4155-db69-a59b58354925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.267162928467176\n"
     ]
    }
   ],
   "source": [
    "# Example 2 for covariance calculation\n",
    "# Covariance can be calculated with statistics module\n",
    "#statistics.covariance(scaled_salaries, standardized_salary)\n",
    "cov = statistics.covariance(min_max_scaled, z_score)\n",
    "print(cov) \n",
    "# Note to Professor: \n",
    "# I'm not sure why I'm getting 0.2672 and not 0.2685 like you did. \n",
    "# Can you please take a look if I did something incorrectly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05ZbMdETUWjH"
   },
   "source": [
    "Exercise 8(b) The Pearson correlation coefficient between the standardized and normalized data (this is actually 1, but due to rounding along the way, the result will be slightly less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730912065242,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "O4_QZQSiUWti",
    "outputId": "59c9ee1d-b25a-4762-eef8-b5fd1304b0b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "# Correlation can be calculated with statistics module\n",
    "corr = statistics.correlation(min_max_scaled,z_score)\n",
    "print(corr)\n",
    "# The result is 1 because we are checking relationship of the same data in different format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFwZeqeNFmEF"
   },
   "source": [
    "Note. Getting a correlation of 1 is often very rare, but in this case, we are basically using the same raw data and simply normalized it (force values to 0,1 range) or standardized it (force the data to centered around zero and then deviate from zero) to put it on a common scale. It will not change the strength or direction of the relationship between 2 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fRAYGUiYR-Y"
   },
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1730912065374,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "BTyXPVUXYnmf"
   },
   "outputs": [],
   "source": [
    "# The default code to run if you setup your book_env correctly to import the dataset\n",
    "# df = pd.read_csv('../../ch_02/data/parsed.csv')\n",
    "\n",
    "# If you encountered issues due to directory setup, you can provide the full file path also\n",
    "# df = pd.read_csv('cdrive../../ch_02/data/parsed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FRq1jddLGOu"
   },
   "source": [
    "## Chapter 2, Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQby6KH3ZKFD"
   },
   "source": [
    "Find the 95th percentile of earthquake magnitude in Japan using the mb magnitude type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1730912065374,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "qnJTCJfWLPp8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/parsed.csv')\n",
    "df.head()\n",
    "earthquake = df[df['type'] == 'earthquake' ]\n",
    "mb = earthquake.loc[earthquake['parsed_place'] == 'Japan','mag']\n",
    "print(round(stats.scoreatpercentile(mb,95),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48KRPKXPLP0l"
   },
   "source": [
    "## Chapter 2, Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufEtJ-4MZNX1"
   },
   "source": [
    "Find the percentage of earthquakes in Indonesia that were coupled with tsunamis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730912065374,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "rZU8KoZvLP77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.13%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/parsed.csv')\n",
    "df.head()\n",
    "earthquake = df[df['type'] == 'earthquake' ]\n",
    "indonesia = earthquake.loc[earthquake['parsed_place'] == 'Indonesia']\n",
    "# a = earthquakes in Indonesia with tsunami\n",
    "# b = earthquakes in Indonesia without tsunami\n",
    "a = len(indonesia[indonesia['tsunami']==1])\n",
    "b = len(indonesia[indonesia['tsunami']==0])\n",
    "print(str(round((a/(a+b))*100,2)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-NBh4nRLQEv"
   },
   "source": [
    "## Chapter 2, Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-WStuWaZQMO"
   },
   "source": [
    "Calculate summary statistics for earthquakes in Nevada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730912065374,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "igev2V45LQL1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cdi</th>\n",
       "      <th>dmin</th>\n",
       "      <th>felt</th>\n",
       "      <th>gap</th>\n",
       "      <th>mag</th>\n",
       "      <th>mmi</th>\n",
       "      <th>nst</th>\n",
       "      <th>rms</th>\n",
       "      <th>sig</th>\n",
       "      <th>time</th>\n",
       "      <th>tsunami</th>\n",
       "      <th>tz</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>6.470000e+02</td>\n",
       "      <td>647.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>6.470000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.421429</td>\n",
       "      <td>0.163155</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>154.436615</td>\n",
       "      <td>0.437311</td>\n",
       "      <td>2.84</td>\n",
       "      <td>12.704791</td>\n",
       "      <td>0.140627</td>\n",
       "      <td>9.146832</td>\n",
       "      <td>1.538318e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-480.0</td>\n",
       "      <td>1.538409e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.514675</td>\n",
       "      <td>0.161793</td>\n",
       "      <td>4.783787</td>\n",
       "      <td>69.474945</td>\n",
       "      <td>0.653397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.052695</td>\n",
       "      <td>0.056765</td>\n",
       "      <td>17.939055</td>\n",
       "      <td>5.954980e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.991682e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.140000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.537247e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-480.0</td>\n",
       "      <td>1.537323e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>97.295000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>2.84</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.537859e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-480.0</td>\n",
       "      <td>1.537928e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>150.040000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.84</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.142900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.538286e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-480.0</td>\n",
       "      <td>1.538428e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.515000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.84</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.181050</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.538824e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-480.0</td>\n",
       "      <td>1.538878e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.300000</td>\n",
       "      <td>1.414000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>355.910000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>2.84</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>1.539461e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-480.0</td>\n",
       "      <td>1.539483e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cdi        dmin       felt         gap         mag   mmi  \\\n",
       "count  14.000000  647.000000  14.000000  647.000000  647.000000  1.00   \n",
       "mean    2.421429    0.163155   2.500000  154.436615    0.437311  2.84   \n",
       "std     0.514675    0.161793   4.783787   69.474945    0.653397   NaN   \n",
       "min     2.000000    0.001000   1.000000   29.140000   -0.500000  2.84   \n",
       "25%     2.000000    0.053000   1.000000   97.295000   -0.100000  2.84   \n",
       "50%     2.200000    0.109000   1.000000  150.040000    0.300000  2.84   \n",
       "75%     3.000000    0.223000   1.000000  200.515000    0.800000  2.84   \n",
       "max     3.300000    1.414000  19.000000  355.910000    2.900000  2.84   \n",
       "\n",
       "              nst         rms         sig          time  tsunami     tz  \\\n",
       "count  647.000000  647.000000  647.000000  6.470000e+02    647.0  647.0   \n",
       "mean    12.704791    0.140627    9.146832  1.538318e+12      0.0 -480.0   \n",
       "std     10.052695    0.056765   17.939055  5.954980e+08      0.0    0.0   \n",
       "min      3.000000    0.000500    0.000000  1.537247e+12      0.0 -480.0   \n",
       "25%      6.000000    0.104400    0.000000  1.537859e+12      0.0 -480.0   \n",
       "50%      9.000000    0.142900    1.000000  1.538286e+12      0.0 -480.0   \n",
       "75%     16.000000    0.181050   10.000000  1.538824e+12      0.0 -480.0   \n",
       "max     61.000000    0.340000  129.000000  1.539461e+12      0.0 -480.0   \n",
       "\n",
       "            updated  \n",
       "count  6.470000e+02  \n",
       "mean   1.538409e+12  \n",
       "std    5.991682e+08  \n",
       "min    1.537323e+12  \n",
       "25%    1.537928e+12  \n",
       "50%    1.538428e+12  \n",
       "75%    1.538878e+12  \n",
       "max    1.539483e+12  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/parsed.csv')\n",
    "df.head()\n",
    "earthquake = df[df['type'] == 'earthquake' ]\n",
    "nevada = earthquake.loc[earthquake['parsed_place'] == 'Nevada']\n",
    "nevada.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aixbtG2sLQS1"
   },
   "source": [
    "## Chapter 2, Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQB0Ho7wZSWE"
   },
   "source": [
    "Add a column indicating whether the earthquake happened in a country or US state that is on the Ring of Fire. Use Alaska, Antarctica (look for Antarctic), Bolivia, California, Canada, Chile, Costa Rica, Ecuador, Fiji, Guatemala, Indonesia, Japan, Kermadec Islands, Mexico (be careful not to select New Mexico), New Zealand, Peru, Philippines, Russia, Taiwan, Tonga, and Washington."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730912065374,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "G1ShxeKDLQZm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert</th>\n",
       "      <th>cdi</th>\n",
       "      <th>code</th>\n",
       "      <th>detail</th>\n",
       "      <th>dmin</th>\n",
       "      <th>felt</th>\n",
       "      <th>gap</th>\n",
       "      <th>ids</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>tsunami</th>\n",
       "      <th>type</th>\n",
       "      <th>types</th>\n",
       "      <th>tz</th>\n",
       "      <th>updated</th>\n",
       "      <th>url</th>\n",
       "      <th>parsed_place</th>\n",
       "      <th>ring_of_fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37389218</td>\n",
       "      <td>https://earthquake.usgs.gov/fdsnws/event/1/que...</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>,ci37389218,</td>\n",
       "      <td>1.35</td>\n",
       "      <td>ml</td>\n",
       "      <td>...</td>\n",
       "      <td>1539475168010</td>\n",
       "      <td>M 1.4 - 9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>,geoserve,nearby-cities,origin,phase-data,</td>\n",
       "      <td>-480.0</td>\n",
       "      <td>1539475395144</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/eventp...</td>\n",
       "      <td>California</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37389202</td>\n",
       "      <td>https://earthquake.usgs.gov/fdsnws/event/1/que...</td>\n",
       "      <td>0.020030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>,ci37389202,</td>\n",
       "      <td>1.29</td>\n",
       "      <td>ml</td>\n",
       "      <td>...</td>\n",
       "      <td>1539475129610</td>\n",
       "      <td>M 1.3 - 9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>,geoserve,nearby-cities,origin,phase-data,</td>\n",
       "      <td>-480.0</td>\n",
       "      <td>1539475253925</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/eventp...</td>\n",
       "      <td>California</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.4</td>\n",
       "      <td>37389194</td>\n",
       "      <td>https://earthquake.usgs.gov/fdsnws/event/1/que...</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>,ci37389194,</td>\n",
       "      <td>3.42</td>\n",
       "      <td>ml</td>\n",
       "      <td>...</td>\n",
       "      <td>1539475062610</td>\n",
       "      <td>M 3.4 - 8km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>,dyfi,focal-mechanism,geoserve,nearby-cities,o...</td>\n",
       "      <td>-480.0</td>\n",
       "      <td>1539536756176</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/eventp...</td>\n",
       "      <td>California</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37389186</td>\n",
       "      <td>https://earthquake.usgs.gov/fdsnws/event/1/que...</td>\n",
       "      <td>0.026180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>,ci37389186,</td>\n",
       "      <td>0.44</td>\n",
       "      <td>ml</td>\n",
       "      <td>...</td>\n",
       "      <td>1539474978070</td>\n",
       "      <td>M 0.4 - 9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>,geoserve,nearby-cities,origin,phase-data,</td>\n",
       "      <td>-480.0</td>\n",
       "      <td>1539475196167</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/eventp...</td>\n",
       "      <td>California</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73096941</td>\n",
       "      <td>https://earthquake.usgs.gov/fdsnws/event/1/que...</td>\n",
       "      <td>0.077990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.0</td>\n",
       "      <td>,nc73096941,</td>\n",
       "      <td>2.16</td>\n",
       "      <td>md</td>\n",
       "      <td>...</td>\n",
       "      <td>1539474716050</td>\n",
       "      <td>M 2.2 - 10km NW of Avenal, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>,geoserve,nearby-cities,origin,phase-data,scit...</td>\n",
       "      <td>-480.0</td>\n",
       "      <td>1539477547926</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/eventp...</td>\n",
       "      <td>California</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  alert  cdi      code                                             detail  \\\n",
       "0   NaN  NaN  37389218  https://earthquake.usgs.gov/fdsnws/event/1/que...   \n",
       "1   NaN  NaN  37389202  https://earthquake.usgs.gov/fdsnws/event/1/que...   \n",
       "2   NaN  4.4  37389194  https://earthquake.usgs.gov/fdsnws/event/1/que...   \n",
       "3   NaN  NaN  37389186  https://earthquake.usgs.gov/fdsnws/event/1/que...   \n",
       "4   NaN  NaN  73096941  https://earthquake.usgs.gov/fdsnws/event/1/que...   \n",
       "\n",
       "       dmin  felt    gap           ids   mag magType  ...           time  \\\n",
       "0  0.008693   NaN   85.0  ,ci37389218,  1.35      ml  ...  1539475168010   \n",
       "1  0.020030   NaN   79.0  ,ci37389202,  1.29      ml  ...  1539475129610   \n",
       "2  0.021370  28.0   21.0  ,ci37389194,  3.42      ml  ...  1539475062610   \n",
       "3  0.026180   NaN   39.0  ,ci37389186,  0.44      ml  ...  1539474978070   \n",
       "4  0.077990   NaN  192.0  ,nc73096941,  2.16      md  ...  1539474716050   \n",
       "\n",
       "                           title  tsunami        type  \\\n",
       "0  M 1.4 - 9km NE of Aguanga, CA        0  earthquake   \n",
       "1  M 1.3 - 9km NE of Aguanga, CA        0  earthquake   \n",
       "2  M 3.4 - 8km NE of Aguanga, CA        0  earthquake   \n",
       "3  M 0.4 - 9km NE of Aguanga, CA        0  earthquake   \n",
       "4  M 2.2 - 10km NW of Avenal, CA        0  earthquake   \n",
       "\n",
       "                                               types     tz        updated  \\\n",
       "0         ,geoserve,nearby-cities,origin,phase-data, -480.0  1539475395144   \n",
       "1         ,geoserve,nearby-cities,origin,phase-data, -480.0  1539475253925   \n",
       "2  ,dyfi,focal-mechanism,geoserve,nearby-cities,o... -480.0  1539536756176   \n",
       "3         ,geoserve,nearby-cities,origin,phase-data, -480.0  1539475196167   \n",
       "4  ,geoserve,nearby-cities,origin,phase-data,scit... -480.0  1539477547926   \n",
       "\n",
       "                                                 url  parsed_place  \\\n",
       "0  https://earthquake.usgs.gov/earthquakes/eventp...    California   \n",
       "1  https://earthquake.usgs.gov/earthquakes/eventp...    California   \n",
       "2  https://earthquake.usgs.gov/earthquakes/eventp...    California   \n",
       "3  https://earthquake.usgs.gov/earthquakes/eventp...    California   \n",
       "4  https://earthquake.usgs.gov/earthquakes/eventp...    California   \n",
       "\n",
       "  ring_of_fire  \n",
       "0         True  \n",
       "1         True  \n",
       "2         True  \n",
       "3         True  \n",
       "4         True  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = ['Alaska','Pacific-Antarctic Ridge','Western Indian-Antarctic Ridge','Bolivia','California','Canada','Chile','CostaRica','Ecuador','Fiji','Guatemala','Indonesia','Japan','Kermadec Islands','Mexico','New Zealand','Peru','Philippines','Russia','Taiwan','Tonga','Washington']\n",
    "df = pd.read_csv('data/parsed.csv')\n",
    "df['ring_of_fire'] = df.parsed_place.isin(list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wn3PdjvwLQiU"
   },
   "source": [
    "## Chapter 2, Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0tPULyCZU1g"
   },
   "source": [
    "Calculate the number of earthquakes in the Ring of Fire locations and the number outside of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730912065374,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "FMnEKjxBLeGc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7003\n",
      "2078\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "df = df[df['type'] == 'earthquake']\n",
    "print(len(df[df['ring_of_fire'] == True])) # earthquakes inside of Ring of Fire\n",
    "print(len(df[df['ring_of_fire'] == False])) # earthquakes outside of Ring of Fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzX_YeGMLd8l"
   },
   "source": [
    "## Chapter 2, Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0y72qXG4ZXfR"
   },
   "source": [
    "Find the tsunami count along the Ring of Fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730912065374,
     "user": {
      "displayName": "Cary J.",
      "userId": "06440680599972585425"
     },
     "user_tz": 360
    },
    "id": "oJLCFZ2QLQpH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "df = pd.read_csv('data/parsed.csv')\n",
    "df = df[df['type'] == 'earthquake']\n",
    "df['ring_of_fire'] = df.parsed_place.isin(list)\n",
    "print(len(df[df['tsunami']==1]))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1G4T3WDZYCMbgPK0ACwH7-OkLcYJNdNXr",
     "timestamp": 1730836441720
    },
    {
     "file_id": "1hr4FI79FUH81MW3-ZOBEl6BqUzUQwIJ7",
     "timestamp": 1730828072456
    },
    {
     "file_id": "1UeUWtcSKsyLbNgr0aOFlkooieHGrLJDf",
     "timestamp": 1711414326026
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
